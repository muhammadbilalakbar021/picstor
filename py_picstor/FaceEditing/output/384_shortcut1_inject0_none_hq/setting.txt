{
    "enc_dim":64,
    "attr_path":"./data/list_attr_celeba.txt",
    "num_workers":0,
    "dec_acti":"relu",
    "n_attrs":13,
    "experiment_name":"384_shortcut1_inject0_none_hq",
    "dis_acti":"lrelu",
    "mode":"wgan",
    "multi_gpu":false,
    "dec_norm":"batchnorm",
    "enc_acti":"lrelu",
    "enc_norm":"batchnorm",
    "beta1":0.5,
    "dis_fc_acti":"relu",
    "beta2":0.999,
    "data_path":"./data/celeba-hq/celeba-384",
    "dis_fc_dim":1024,
    "epochs":200,
    "n_samples":16,
    "inject_layers":0,
    "save_interval":1000,
    "data":"CelebA-HQ",
    "dec_dim":64,
    "gpu":true,
    "dis_fc_norm":"none",
    "batch_size":8,
    "sample_interval":1000,
    "lr_base":0.0002,
    "lr":0.0002,
    "thres_int":0.5,
    "dis_dim":64,
    "attrs":[
        "Bald",
        "Bangs",
        "Black_Hair",
        "Blond_Hair",
        "Brown_Hair",
        "Bushy_Eyebrows",
        "Eyeglasses",
        "Male",
        "Mouth_Slightly_Open",
        "Mustache",
        "No_Beard",
        "Pale_Skin",
        "Young"
    ],
    "image_list_path":"./data/image_list.txt",
    "betas":[
        0.5,
        0.999
    ],
    "shortcut_layers":1,
    "dis_layers":5,
    "img_size":384,
    "test_int":1.0,
    "enc_layers":5,
    "b_distribution":"none",
    "dec_layers":5,
    "dis_norm":"instancenorm",
    "lambda_1":100.0,
    "lambda_2":10.0,
    "lambda_3":1.0,
    "lambda_gp":10.0,
    "n_d":5
}
